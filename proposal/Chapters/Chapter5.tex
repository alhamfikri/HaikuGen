

\section{Methodology}


The brief concept of implementing Haiku generator is by learning the grammatical pattern and rules of existing Haiku poems and build a new grammar skeleton based on it. The generator will select words to fill in the grammar skeleton based on the statistical approach. Other resources such as CMUPD and WordNet will be supporting the decision making of words selection.


\subsection{PoS Tag Extraction}


In this phase, we apply PoS tagger algorithm for every collected Haiku poems. Therefore, in this phase we aim to acquire a list of grammar tag pattern. We are only interested in the grammar tag, therefore we can remove the Haiku after tagging. One simple illustration of this process is provided in table \ref{exmpl}:


\begin{table}[h]

\centering

\begin{tabular}{|c|c|}

\hline Haiku & Extracted PoS Tag Information \\

\hline Three strokes of lightning & CD NNS IN NN \\ 

One hit mountain frightening &  CD NN NN JJ  \\ 

Dark clouds thunder loud &  JJ NNS NN RB \\ 

\hline

\end{tabular} 

\caption{The Example of an Extracted PoS Tag Information of the Haiku}

\label{exmpl}

\end{table}


The reason for choosing this method over grammar tree or context free grammar is because sometimes poetry does not follow standard grammar rules. By using formal grammar rule, we might achieve a less poetic result. By learning from existing Haiku, we hope that we are able to capture the grammatical pattern used in Haiku.


\subsection{Creating Haiku: Grammar Skeleton}


Grammar skeleton is a sequence of tags that will be used to create a Haiku. The generated Haiku should follow the grammar tag defined by the skeleton. In this phase, the grammar skeleton is created by combining several tag patterns in the previous part.




\begin{table}[h]

\centering

\begin{tabular}{|c|c|c|}

\hline Pattern 1 & Pattern 2 & Pattern 3 \\

\hline CD NNS IN NN & DT NNS IN NNP &\textbf{ JJ JJ NN} \\ 

\textbf{CD NN NN JJ} & JJ NN CC JJ NNS & VBG IN DT NN IN NN \\ 

JJ NNS NN RB & \textbf{VBG DT NN} & NN IN\\ 

\hline

\end{tabular} 

~\\

$\downarrow$

~\\

\begin{tabular}{|c|}

\hline Generated Skeleton \\

\hline  

JJ JJ NN  \\ 

JJ NNS NN RB \\ 

VBG DT NN \\

\hline

\end{tabular} 

\caption{The Example of a Grammar Skeleton Creation Process}

\label{exmpl2}


\end{table}


Illustration of creating a grammar skeleton based on tag data is shown above. Some base grammar patterns are randomly chosen as parents. The grammar skeleton is generated by applying crossover from the parents. In this example, each parent inherits one line of grammar pattern. In the implementation, the rule is not strictly forced the generation made by three parents. Therefore, more or fewer parents are possible.


\subsection{Creating Haiku: Word Filling}


Haiku will be constructed with previously defined grammar skeleton as its basis. For each speech tag, we look up word with an exactly same label and fill in the slot with the chosen word. Our word resource comes from a various corpus. Although some corpus such as Brown corpus has already annotated with speech tagging, we need to apply identical PoS tagger algorithm that used in constructing the skeleton for speech label consistency. To enrich our dictionary, WordNet will be used to paraphrase and replace some words in the corpus with different but related terms. 


In some situation, a user will provide the system with some keywords. In this case, the keywords will be tagged as well before further processing. Our tagged keyword will be placed in the skeleton first, before applying general word filling. Again, WordNet can be used to transform user keywords into another similar term.


Word filling is not randomly choose any words with required speech tag. It follows haiku rule constraints and meaning constraints. The word must be chosen in particular so that it satisfy the syllables rule. In case of strict use of \textit{kiregi} and/or \textit{kigo}, those words must exist in generated haiku. Meaning constraints is on how to chose correlated words and have actual meaning. We want to make the resource usage remains minimum, therefore we choose a word if it is statistically correlated with one of some previously placed words.



\subsection{Creating Haiku: Scoring}


In this part, generated haiku will be scored to determine its quality. We use the restricted definition of poetry by \citeauthor{manurung2004evolutionary} where a poem should be meaningful, grammatically correct, and poetic. As the haiku is generated based on previously defined grammar, we can remove the second factor as a score. Therefore, our scoring consists of two parts: Meaningfulness and beautifulness. 


Meaningfulness score $M$ is calculated by a statistical approach. The haiku will be scored based on a statistical relationship of each word, and word to word relationship. Beautifulness score $B$ is defined by some phonetic features that could be extracted from the haiku such as rhymes, stress pattern, etc.


\begin{table}[h]

\centering

\begin{tabular}{c}


$S = w_mM + w_bB$

\\

\end{tabular} 


\end{table}



The score will be a weighted sum of both components, as defined in the formula above. Therefore, higher $w_m$ leads to more 'meaningful' Haiku and higher $w_b$ leads to more 'poetic' Haiku. The composition of the weights is another important research part. The challenge is how to determine the weight so that the generate haiku is not too statistically meaningful so that it only produces common sentence, but not too 'creative' so that it does not make sense at all. 

This score can be used as ranking parameter of the generated Haiku. The system will generate Haikus for a pre-defined time and sort them based on their scores. The system will choose Haiku with the best score as the output. To add more variations, we can also choose a random Haiku from top-K in our sorted list.