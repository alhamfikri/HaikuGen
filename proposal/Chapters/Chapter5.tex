\section{Methodology}

The brief concept of implementing Haiku generator is by learning the grammatical pattern and rules of existing Haiku poems and build a new grammar skeleton based on it. The generator will select words to fill-in the grammar skeleton based on statistical approach. Other resources such as CMUPD and WordNet will be supporting the decision making of words selection.

\subsection{PoS Tag Extraction}

In this phase we apply PoS tagger algorithm for every collected Haiku poems. Therefore, in this phase we aim to acquire list of grammar tag pattern. We are only interested in the grammar tag, therefore we can remove the Haiku after tagging. One simple illustration of this process is provided in table \ref{exmpl}:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline Haiku & Extracted PoS Tag Information \\
		\hline Three strokes of lightning & CD NNS IN NN \\ 
		One hit mountain frightening &  CD NN NN JJ  \\ 
		Dark clouds thunder loud &  JJ NNS NN RB \\ 
		\hline
	\end{tabular} 
	\caption{Example of extracted PoS tag information of the Haiku}
	\label{exmpl}
\end{table}
	
The reason of choosing this method over using grammar tree or context free grammar is because sometimes poetry does not follow standard grammar rules. By using formal grammar rule, we might achieve less poetic result. By learning from existing Haiku, we hope that we are able to capture the grammatical pattern used in Haiku.

\subsection{Creating Haiku: Grammar Skeleton}

Grammar skeleton is sequence of tags that will be used to create a Haiku. The generated Haiku should follow the grammar tag defined by the skeleton. In this phase, grammar skeleton is created by combining several tag patterns in previous part.



\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline Pattern 1 & Pattern 2 & Pattern 3 \\
		\hline CD NNS IN NN & DT NNS IN NNP &\textbf{ JJ JJ NN} \\ 
		 \textbf{CD NN NN JJ} & JJ NN CC JJ NNS & VBG IN DT NN IN NN \\ 
		 JJ NNS NN RB & \textbf{VBG DT NN} & NN IN\\ 
		\hline
	\end{tabular} 
	\\
	$\downarrow$
	\\
	\begin{tabular}{|c|}
			\hline Generated Skeleton \\
			\hline  
			 JJ JJ NN  \\ 
			  JJ NNS NN RB \\ 
			  VBG DT NN \\
			\hline
		\end{tabular} 
\end{table}

Illustration of creating a grammar skeleton based on tag data is shown above. Some basis grammar patterns are randomly chosen as parents. The grammar skeleton is generated by applying crossover from the parents. In this example, each parent inherits one line of grammar pattern. In the implementation, the rule is not strictly forced the generation made by three parents. Therefore more or less parents is possible.

\subsection{Creating Haiku: Word Filling}

Haiku will be constructed with previously defined grammar skeleton as its basis. For each speech tag, we look up word with exactly same label and fill in the slot with the chosen word. Our word resource comes from various corpus. Although some corpus such as Brown corpus has already annotated with speech tagging, we need to apply identical PoS tagger algorithm that used in constructing the skeleton for speech label consistency. To enrich our dictionary, WordNet will be used to paraphrase and replace some words in corpus with different but related terms. 

In some situation user will provide the system with some keywords. In this case, the keywords will be tagged as well before further processing. Our tagged keyword will be placed in the skeleton first, before applying general word filling. Again, WordNet can be used to transform user keywords into another similar term.

Word filling is not randomly choose any words with required speech tag. It follows haiku rule constraints and meaning constraints. The word must be chosen in particular so that it satisfy the syllables rule. In case of strict use of \textit{kiregi} and/or \textit{kigo}, those words must exists in generated haiku. Meaning constrains is on how to chose correlated words and have actual meaning. We want to make the resource usage remains minimum, therefore we choose a word if it is statistically correlated with one of some previously placed words.


\subsection{Creating Haiku: Scoring}

In this part, generated haiku will be scored to determine its quality. We use the restricted definition of poetry by \citeauthor{manurung2004evolutionary} where a poem should be meaningful, grammatically correct, and poetic. As the haiku is generated based on previously defined grammar, we can remove the second factor as a score. Therefore, our scoring consists of two parts: Meaningfulness and beautifulness. 

Meaningfulness score $M$ is calculated by statistical approach. The haiku will be scored based on statistical relationship of each word, and word to word relationship. Beautifulness score $B$ is defined by some phonetic features that could be extracted from the haiku such as rhymes, stress pattern, etc.

\begin{table}[h]
	\centering
	\begin{tabular}{c}

		$S = w_mM + w_bB$
		\\
	\end{tabular} 
	
\end{table}


The score will be a weighted sum of both components, as defined in formula above. Therefore, higher $w_m$ leads to more 'meaningful' Haiku and higher $w_b$ leads to more 'poetic' Haiku. The composition of the weights is another important research part. The challenge is how to determine the weight so that the generate haiku is not too statistically meaningful so that it only produces common sentence, but not too 'creative' so that it does not make sense at all. 

This score can be used as quality threshold to make sure our generated haiku result good. The system will reject any generated haiku lower than some defined threshold and keep generating until its score requirement is satisfied.